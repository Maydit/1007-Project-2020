{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text_processing_all_PG-annotations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pedrogalarza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get list of stopwords from NLTK package\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(df, startdate = 20200811, no_stops = True):\n",
    "\n",
    "    ## Define dataframe and filter by date\n",
    "    df = df[['id', 'date', 'tweet']]\n",
    "    df = df[df.index > parser.parse(str(startdate))]\n",
    "    \n",
    "    ## Clean tweets\n",
    "    clean_text = []\n",
    "\n",
    "    for tweet in df.tweet:\n",
    "        # Remove URLS\n",
    "        tweet = re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "        # Replace non-characters with spaces\n",
    "        tweet = re.sub(\"\\W\", \" \", tweet)\n",
    "        # Remove digits\n",
    "        tweet = re.sub(\"[0-9]\", \"\", tweet)\n",
    "        # Remove extra spaces\n",
    "        tweet = re.sub(\"\\s+\", \" \", tweet)\n",
    "        tweet = re.sub(\"^\\s+\", \"\", tweet)\n",
    "        tweet = re.sub(\"\\s+$\", \"\", tweet)\n",
    "            \n",
    "        clean_text.append(tweet.lower())\n",
    "\n",
    "    ## Add updated text to main data\n",
    "    df['clean_text'] = clean_text\n",
    "    df['term_list'] = df['clean_text'].apply(lambda x: x.split())\n",
    "    \n",
    "    ## Remove stop words from tweets\n",
    "    if no_stops == True:\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        \n",
    "        for term_list in df['term_list']:\n",
    "            for term in term_list:\n",
    "                if term in stop_words:\n",
    "                    term_list.remove(term)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(x):\n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates a counter object (dictionary like) associating a term present in a document with its normalized frequncy. Helper fucntion for the TF-IDF calculation.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        x -           2-dimentional array like object containing the list of all terms in the 0-index and a collection object containing the term counts in the 1-index.\n",
    "\n",
    "    '''\n",
    "    wordFreq = x[1]\n",
    "    wordList = x[0]\n",
    "    bagOfWordsCount = len(wordList)\n",
    "    \n",
    "    tfDict = {}\n",
    "    for word, count in wordFreq.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "        \n",
    "    return Counter(tfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_counter(txt_list):\n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates and returns a counter object (dictionary-like) of the counts of each unique term from a list of terms.  The keys of the dictionary \n",
    "    are the unique terms and the values are the counts of that term.  Helper fucntion for the TF-IDF calculation.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        x -           list of string values.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    term_counts = {}\n",
    "    for i in set(txt_list):\n",
    "        term_counts[i] = txt_list.count(i)\n",
    "        \n",
    "    return(Counter(term_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_term_count_list(df, term_count_column = \"term_count\"):\n",
    "    \n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates and returns a list of all frequncy count counter objects (dictionary like) from a data frame column containing frequency count objects. Helper fucntion for the TF-IDF calculation.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        df -                    dataframe containing column with frequency counts as counter objects as entries.\n",
    "        \n",
    "        term_count_column -     name of columns containing frequency counts.\n",
    "    '''\n",
    "   \n",
    "    term_count_list = []\n",
    "    for i in df[term_count_column]:\n",
    "        term_count_list.append(dict(i))\n",
    "        \n",
    "    return(term_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_corpus_set(df, term_list_column = \"term_list\"):\n",
    "\n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates and returns a set of all unique terms found across the union of all documnets (the corpus). Helper fucntion for the TF-IDF calculation.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        df -                    dataframe containing column with frequency counts as counter objects as entries.\n",
    "        \n",
    "        term_count_column -     name of column containing frequency counts.\n",
    "    '''\n",
    "    \n",
    "    tweet_corpus = []\n",
    "    for i in df[term_list_column]:\n",
    "        tweet_corpus += i\n",
    "\n",
    "    return(set(tweet_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents, corpus_set):\n",
    "    \n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates the inverse document frequency score (IDF) for all terms in the corpus. Helper fucntion for the TF-IDF calculation.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        documents -      list of counter objects containing the frequency counts for each document.\n",
    "        \n",
    "        corpus_set -     set of all unique terms found across the union of all documnets (the corpus).\n",
    "    '''\n",
    "    \n",
    "    N = len(documents)\n",
    "\n",
    "    idfDict = dict.fromkeys(corpus_set, 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / (float(val)))\n",
    "        \n",
    "    return(Counter(idfDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(TF,idfs):\n",
    "    \n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates the term frequency/inverse document frequency (TF-IDF score) for each unique term in a document.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        TF -      Counter object containing the term frequncy values for each document\n",
    "        \n",
    "        idfs -    Counter object containing the inverse document frequency score (IDF) for all temrs unqiue in the corpus.\n",
    "    '''\n",
    "    \n",
    "    tfidf = {}\n",
    "    for word, val in TF.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "        \n",
    "    return(Counter(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_processing(df):\n",
    "    \n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Uses the associated helper functions to calculate the TF-IDF scores for a dataframe of documents.\n",
    "    Returns a 3-dimentional array containing:\n",
    "        - [0] a data frame with the TF-IDF scores, TF scores, term-list, processed document, and term cou,t.\n",
    "        - [1] the idf scores for all terms in the corpus\n",
    "        - [2] the corpus of the document\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        df -      dataframe of processed documents,\n",
    "    '''\n",
    "    \n",
    "    df = clean_tweets(df)\n",
    "\n",
    "    # Create dictionary of term counts for each tweet\n",
    "    df['term_count'] = df['term_list'].apply(lambda x: term_counter(x))\n",
    "    \n",
    "    # Calculate term frequency (TF)\n",
    "    df['TF'] = df[['term_list', 'term_count']].apply(computeTF, axis = 1)\n",
    "    \n",
    "    # Return corpus and doc list\n",
    "    term_count_list_df = return_term_count_list(df)\n",
    "    corpus_set_df = return_corpus_set(df)\n",
    "    \n",
    "    # Calculate IDF and  TF-IDF\n",
    "    df_idf = computeIDF(term_count_list_df, corpus_set_df)\n",
    "    df['TFIDF'] = df['TF'].apply(lambda x: computeTFIDF(x, df_idf))\n",
    "    \n",
    "    return(df, df_idf, corpus_set_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_normalize_collections(counter_list):\n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Generates an aggregate tfidf score counter object from a list of counter objects.  Takes the sum of all TF_IDF scores with respect to term objects\n",
    "    and then divides by the number of dictionaries in the list.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        counter_list -     list of counter objects that contain TF-IDF scores.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    counter_sum = Counter()\n",
    "    for counter in counter_list:\n",
    "        counter_sum += counter\n",
    "        \n",
    "    for k,v in counter_sum.items():\n",
    "        counter_sum[k] = v/len(counter_list)\n",
    "        \n",
    "    return(counter_sum.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_vecorization(df,corpus):\n",
    "    '''\n",
    "    Purpose:\n",
    "    -------\n",
    "    Vecotrizes the tf-idf scores.  Not advised.\n",
    "    \n",
    "    Inputs:\n",
    "    ------\n",
    "        df -      dataframe with tf-idf scores\n",
    "        corpus -  set of unique words across all documents.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    D = np.zeros((len(df), len(corpus)))\n",
    "\n",
    "    for i,tfidf in enumerate(df[\"TFIDF\"]):\n",
    "        for term in tfidf:\n",
    "            ind = (list(corpus)).index(term)\n",
    "            D[i][ind] = tfidf[term]\n",
    "            \n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timezone</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-09 14:40:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1325885871875190784</td>\n",
       "      <td>1325885871875190784</td>\n",
       "      <td>1.604951e+12</td>\n",
       "      <td>-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 14:17:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1325880083618426881</td>\n",
       "      <td>1325880083618426881</td>\n",
       "      <td>1.604949e+12</td>\n",
       "      <td>-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 13:50:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1325873288711712769</td>\n",
       "      <td>1325873288711712769</td>\n",
       "      <td>1.604948e+12</td>\n",
       "      <td>-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 13:37:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1325870017401905152</td>\n",
       "      <td>1325870017401905152</td>\n",
       "      <td>1.604947e+12</td>\n",
       "      <td>-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Today, I have named a COVID-19 Transition Advi...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 11:46:50</th>\n",
       "      <td>4</td>\n",
       "      <td>1325842292444291072</td>\n",
       "      <td>1325842292444291072</td>\n",
       "      <td>1.604940e+12</td>\n",
       "      <td>-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I spent the morning with the co-chairs of my C...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0                   id      conversation_id  \\\n",
       "datetime                                                                    \n",
       "2020-11-09 14:40:00           0  1325885871875190784  1325885871875190784   \n",
       "2020-11-09 14:17:00           1  1325880083618426881  1325880083618426881   \n",
       "2020-11-09 13:50:00           2  1325873288711712769  1325873288711712769   \n",
       "2020-11-09 13:37:00           3  1325870017401905152  1325870017401905152   \n",
       "2020-11-09 11:46:50           4  1325842292444291072  1325842292444291072   \n",
       "\n",
       "                       created_at  timezone  place  \\\n",
       "datetime                                             \n",
       "2020-11-09 14:40:00  1.604951e+12      -500    NaN   \n",
       "2020-11-09 14:17:00  1.604949e+12      -500    NaN   \n",
       "2020-11-09 13:50:00  1.604948e+12      -500    NaN   \n",
       "2020-11-09 13:37:00  1.604947e+12      -500    NaN   \n",
       "2020-11-09 11:46:50  1.604940e+12      -500    NaN   \n",
       "\n",
       "                                                                 tweet  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  The bottom line: I will spare no effort to tur...   \n",
       "2020-11-09 14:17:00  The challenge before us right now is still imm...   \n",
       "2020-11-09 13:50:00  My COVID-19 Transition Advisory Board will adv...   \n",
       "2020-11-09 13:37:00  Today, I have named a COVID-19 Transition Advi...   \n",
       "2020-11-09 11:46:50  I spent the morning with the co-chairs of my C...   \n",
       "\n",
       "                    language hashtags cashtags  ...  user_rt_id  user_rt  \\\n",
       "datetime                                        ...                        \n",
       "2020-11-09 14:40:00       en       []       []  ...         NaN      NaN   \n",
       "2020-11-09 14:17:00       en       []       []  ...         NaN      NaN   \n",
       "2020-11-09 13:50:00       en       []       []  ...         NaN      NaN   \n",
       "2020-11-09 13:37:00       en       []       []  ...         NaN      NaN   \n",
       "2020-11-09 11:46:50       en       []       []  ...         NaN      NaN   \n",
       "\n",
       "                    retweet_id reply_to  retweet_date  translate trans_src  \\\n",
       "datetime                                                                     \n",
       "2020-11-09 14:40:00        NaN       []           NaN        NaN       NaN   \n",
       "2020-11-09 14:17:00        NaN       []           NaN        NaN       NaN   \n",
       "2020-11-09 13:50:00        NaN       []           NaN        NaN       NaN   \n",
       "2020-11-09 13:37:00        NaN       []           NaN        NaN       NaN   \n",
       "2020-11-09 11:46:50        NaN       []           NaN        NaN       NaN   \n",
       "\n",
       "                    trans_dest        date  month  \n",
       "datetime                                           \n",
       "2020-11-09 14:40:00        NaN  2020-11-09     11  \n",
       "2020-11-09 14:17:00        NaN  2020-11-09     11  \n",
       "2020-11-09 13:50:00        NaN  2020-11-09     11  \n",
       "2020-11-09 13:37:00        NaN  2020-11-09     11  \n",
       "2020-11-09 11:46:50        NaN  2020-11-09     11  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Biden data\n",
    "biden_df = pd.read_csv('../../data/biden.csv', index_col = 'date', parse_dates = True)\n",
    "biden_df.index.rename(\"datetime\", inplace = True)\n",
    "\n",
    "## Date variables\n",
    "biden_df['date'] = biden_df.index.date\n",
    "biden_df['month'] = biden_df.index.month\n",
    "\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>device</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-08-02 18:07:48</th>\n",
       "      <td>98454970654916608</td>\n",
       "      <td>Republicans and Democrats have both created ou...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>49</td>\n",
       "      <td>255</td>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-03 01:34:50</th>\n",
       "      <td>1234653427789070336</td>\n",
       "      <td>I was thrilled to be back in the Great city of...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>73748</td>\n",
       "      <td>17404</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 03:22:47</th>\n",
       "      <td>1218010753434820614</td>\n",
       "      <td>RT @CBS_Herridge: READ: Letter to surveillance...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>7396</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-12 20:10:58</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>80527</td>\n",
       "      <td>23502</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 13:13:59</th>\n",
       "      <td>1218159531554897920</td>\n",
       "      <td>RT @MZHemingway: Very friendly telling of even...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>9081</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "datetime                                   \n",
       "2011-08-02 18:07:48    98454970654916608   \n",
       "2020-03-03 01:34:50  1234653427789070336   \n",
       "2020-01-17 03:22:47  1218010753434820614   \n",
       "2020-09-12 20:10:58  1304875170860015617   \n",
       "2020-01-17 13:13:59  1218159531554897920   \n",
       "\n",
       "                                                                 tweet  \\\n",
       "datetime                                                                 \n",
       "2011-08-02 18:07:48  Republicans and Democrats have both created ou...   \n",
       "2020-03-03 01:34:50  I was thrilled to be back in the Great city of...   \n",
       "2020-01-17 03:22:47  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
       "2020-09-12 20:10:58  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "2020-01-17 13:13:59  RT @MZHemingway: Very friendly telling of even...   \n",
       "\n",
       "                    isRetweet isDeleted              device  favorites  \\\n",
       "datetime                                                                 \n",
       "2011-08-02 18:07:48         f         f           TweetDeck         49   \n",
       "2020-03-03 01:34:50         f         f  Twitter for iPhone      73748   \n",
       "2020-01-17 03:22:47         t         f  Twitter for iPhone          0   \n",
       "2020-09-12 20:10:58         f         f  Twitter for iPhone      80527   \n",
       "2020-01-17 13:13:59         t         f  Twitter for iPhone          0   \n",
       "\n",
       "                     retweets        date  month  \n",
       "datetime                                          \n",
       "2011-08-02 18:07:48       255  2011-08-02      8  \n",
       "2020-03-03 01:34:50     17404  2020-03-03      3  \n",
       "2020-01-17 03:22:47      7396  2020-01-17      1  \n",
       "2020-09-12 20:10:58     23502  2020-09-12      9  \n",
       "2020-01-17 13:13:59      9081  2020-01-17      1  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Biden data\n",
    "trump_df = pd.read_csv('../../data/trump.csv', index_col = 'date', parse_dates = True)\n",
    "trump_df.index.rename(\"datetime\", inplace = True)\n",
    "\n",
    "## Date variables\n",
    "trump_df['date'] = trump_df.index.date\n",
    "trump_df['month'] = trump_df.index.month\n",
    "\n",
    "## Match variable names to Biden\n",
    "trump_df.rename(columns = {'text' : 'tweet'}, inplace = True)\n",
    "\n",
    "trump_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>term_list</th>\n",
       "      <th>term_count</th>\n",
       "      <th>TF</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-09 14:40:00</th>\n",
       "      <td>1325885871875190784</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "      <td>the bottom line i will spare no effort to turn...</td>\n",
       "      <td>[bottom, line, will, spare, effort, turn, pand...</td>\n",
       "      <td>{'effort': 1, 'line': 1, 'around': 1, 'will': ...</td>\n",
       "      <td>{'effort': 0.125, 'line': 0.125, 'around': 0.1...</td>\n",
       "      <td>{'effort': 0.7191707468556287, 'line': 0.56257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 14:17:00</th>\n",
       "      <td>1325880083618426881</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "      <td>the challenge before us right now is still imm...</td>\n",
       "      <td>[challenge, us, right, still, immense, growing...</td>\n",
       "      <td>{'challenge': 1, 'is': 1, 'the': 1, 'action': ...</td>\n",
       "      <td>{'challenge': 0.07142857142857142, 'is': 0.071...</td>\n",
       "      <td>{'challenge': 0.37098215620782904, 'is': 0.186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 13:50:00</th>\n",
       "      <td>1325873288711712769</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "      <td>my covid transition advisory board will advise...</td>\n",
       "      <td>[covid, transition, advisory, board, advise, d...</td>\n",
       "      <td>{'a': 1, 'empathy': 1, 'compassion': 1, 'trans...</td>\n",
       "      <td>{'a': 0.05, 'empathy': 0.05, 'compassion': 0.0...</td>\n",
       "      <td>{'a': 0.08845111539186284, 'empathy': 0.302052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 13:37:00</th>\n",
       "      <td>1325870017401905152</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Today, I have named a COVID-19 Transition Advi...</td>\n",
       "      <td>today i have named a covid transition advisory...</td>\n",
       "      <td>[today, have, named, covid, transition, adviso...</td>\n",
       "      <td>{'public': 1, 'a': 1, 'comprised': 1, 'transit...</td>\n",
       "      <td>{'public': 0.03333333333333333, 'a': 0.0333333...</td>\n",
       "      <td>{'public': 0.1365045966080499, 'a': 0.05896741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 11:46:50</th>\n",
       "      <td>1325842292444291072</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>I spent the morning with the co-chairs of my C...</td>\n",
       "      <td>i spent the morning with the co chairs of my c...</td>\n",
       "      <td>[spent, morning, co, chairs, my, covid, counci...</td>\n",
       "      <td>{'status': 1, 'chairs': 1, 'beat': 1, 're': 1,...</td>\n",
       "      <td>{'status': 0.041666666666666664, 'chairs': 0.0...</td>\n",
       "      <td>{'status': 0.2686047148085406, 'chairs': 0.268...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id        date  \\\n",
       "datetime                                               \n",
       "2020-11-09 14:40:00  1325885871875190784  2020-11-09   \n",
       "2020-11-09 14:17:00  1325880083618426881  2020-11-09   \n",
       "2020-11-09 13:50:00  1325873288711712769  2020-11-09   \n",
       "2020-11-09 13:37:00  1325870017401905152  2020-11-09   \n",
       "2020-11-09 11:46:50  1325842292444291072  2020-11-09   \n",
       "\n",
       "                                                                 tweet  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  The bottom line: I will spare no effort to tur...   \n",
       "2020-11-09 14:17:00  The challenge before us right now is still imm...   \n",
       "2020-11-09 13:50:00  My COVID-19 Transition Advisory Board will adv...   \n",
       "2020-11-09 13:37:00  Today, I have named a COVID-19 Transition Advi...   \n",
       "2020-11-09 11:46:50  I spent the morning with the co-chairs of my C...   \n",
       "\n",
       "                                                            clean_text  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  the bottom line i will spare no effort to turn...   \n",
       "2020-11-09 14:17:00  the challenge before us right now is still imm...   \n",
       "2020-11-09 13:50:00  my covid transition advisory board will advise...   \n",
       "2020-11-09 13:37:00  today i have named a covid transition advisory...   \n",
       "2020-11-09 11:46:50  i spent the morning with the co chairs of my c...   \n",
       "\n",
       "                                                             term_list  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  [bottom, line, will, spare, effort, turn, pand...   \n",
       "2020-11-09 14:17:00  [challenge, us, right, still, immense, growing...   \n",
       "2020-11-09 13:50:00  [covid, transition, advisory, board, advise, d...   \n",
       "2020-11-09 13:37:00  [today, have, named, covid, transition, adviso...   \n",
       "2020-11-09 11:46:50  [spent, morning, co, chairs, my, covid, counci...   \n",
       "\n",
       "                                                            term_count  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  {'effort': 1, 'line': 1, 'around': 1, 'will': ...   \n",
       "2020-11-09 14:17:00  {'challenge': 1, 'is': 1, 'the': 1, 'action': ...   \n",
       "2020-11-09 13:50:00  {'a': 1, 'empathy': 1, 'compassion': 1, 'trans...   \n",
       "2020-11-09 13:37:00  {'public': 1, 'a': 1, 'comprised': 1, 'transit...   \n",
       "2020-11-09 11:46:50  {'status': 1, 'chairs': 1, 'beat': 1, 're': 1,...   \n",
       "\n",
       "                                                                    TF  \\\n",
       "datetime                                                                 \n",
       "2020-11-09 14:40:00  {'effort': 0.125, 'line': 0.125, 'around': 0.1...   \n",
       "2020-11-09 14:17:00  {'challenge': 0.07142857142857142, 'is': 0.071...   \n",
       "2020-11-09 13:50:00  {'a': 0.05, 'empathy': 0.05, 'compassion': 0.0...   \n",
       "2020-11-09 13:37:00  {'public': 0.03333333333333333, 'a': 0.0333333...   \n",
       "2020-11-09 11:46:50  {'status': 0.041666666666666664, 'chairs': 0.0...   \n",
       "\n",
       "                                                                 TFIDF  \n",
       "datetime                                                                \n",
       "2020-11-09 14:40:00  {'effort': 0.7191707468556287, 'line': 0.56257...  \n",
       "2020-11-09 14:17:00  {'challenge': 0.37098215620782904, 'is': 0.186...  \n",
       "2020-11-09 13:50:00  {'a': 0.08845111539186284, 'empathy': 0.302052...  \n",
       "2020-11-09 13:37:00  {'public': 0.1365045966080499, 'a': 0.05896741...  \n",
       "2020-11-09 11:46:50  {'status': 0.2686047148085406, 'chairs': 0.268...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate TFIDFs for Biden\n",
    "biden_df, biden_idf,biden_corpus = TFIDF_processing(biden_df)\n",
    "biden_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-08-11    [{'track': 0.2859194361564614, 'on': 0.1992760...\n",
       "2020-08-12    [{'ask': 0.2418537621485437, 'mate': 0.2596875...\n",
       "2020-08-13    [{'days': 3.1323271507324484}, {'for': 0.21567...\n",
       "2020-08-14    [{'america': 0.5778366496656546, 'kamalaharris...\n",
       "2020-08-15    [{'challenge': 0.3246093866818504, 'president'...\n",
       "Name: TFIDF, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate TFIDF scores by date for Biden\n",
    "biden_by_date = biden_df.groupby(\"date\")[\"TFIDF\"].apply(lambda x:x.to_list())\n",
    "\n",
    "score_df_biden = pd.DataFrame(biden_df.groupby(\"date\")[\"TFIDF\"].apply(lambda x: sum_normalize_collections(x.to_list())))\n",
    "\n",
    "score_df_biden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>term_list</th>\n",
       "      <th>term_count</th>\n",
       "      <th>TF</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-12 20:10:58</th>\n",
       "      <td>1304875170860015617</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>The Unsolicited Mail In Ballot Scam is a major...</td>\n",
       "      <td>the unsolicited mail in ballot scam is a major...</td>\n",
       "      <td>[unsolicited, mail, ballot, scam, major, threa...</td>\n",
       "      <td>{'a': 1, 'ballot': 1, 'fraud': 1, 'smaller': 1...</td>\n",
       "      <td>{'a': 0.02857142857142857, 'ballot': 0.0285714...</td>\n",
       "      <td>{'a': 0.06206252854785413, 'ballot': 0.1258794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 22:04:14</th>\n",
       "      <td>1319761576996573186</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>THANK YOU to all of the Great American Patriot...</td>\n",
       "      <td>thank you to all of the great american patriot...</td>\n",
       "      <td>[thank, to, of, great, american, patriots, the...</td>\n",
       "      <td>{'great': 1, 'patriots': 1, 'american': 1, 'th...</td>\n",
       "      <td>{'great': 0.1, 'patriots': 0.1, 'american': 0....</td>\n",
       "      <td>{'great': 0.24709204078132607, 'patriots': 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-12 22:22:39</th>\n",
       "      <td>1315779944002199552</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>“I’m running as a proud Democrat, for the Sena...</td>\n",
       "      <td>i m running as a proud democrat for the senate...</td>\n",
       "      <td>[m, running, a, proud, democrat, the, senate, ...</td>\n",
       "      <td>{'a': 1, 's': 1, 'm': 1, 'sleepy': 1, 'china':...</td>\n",
       "      <td>{'a': 0.045454545454545456, 's': 0.04545454545...</td>\n",
       "      <td>{'a': 0.09873584087158611, 's': 0.153130090955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 19:50:48</th>\n",
       "      <td>1319727996882702336</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>https://t.co/LCQcdlRkhz</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23 19:49:55</th>\n",
       "      <td>1319727773234069505</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>https://t.co/4V7nu5hh8V</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id        date  \\\n",
       "datetime                                               \n",
       "2020-09-12 20:10:58  1304875170860015617  2020-09-12   \n",
       "2020-10-23 22:04:14  1319761576996573186  2020-10-23   \n",
       "2020-10-12 22:22:39  1315779944002199552  2020-10-12   \n",
       "2020-10-23 19:50:48  1319727996882702336  2020-10-23   \n",
       "2020-10-23 19:49:55  1319727773234069505  2020-10-23   \n",
       "\n",
       "                                                                 tweet  \\\n",
       "datetime                                                                 \n",
       "2020-09-12 20:10:58  The Unsolicited Mail In Ballot Scam is a major...   \n",
       "2020-10-23 22:04:14  THANK YOU to all of the Great American Patriot...   \n",
       "2020-10-12 22:22:39  “I’m running as a proud Democrat, for the Sena...   \n",
       "2020-10-23 19:50:48                            https://t.co/LCQcdlRkhz   \n",
       "2020-10-23 19:49:55                            https://t.co/4V7nu5hh8V   \n",
       "\n",
       "                                                            clean_text  \\\n",
       "datetime                                                                 \n",
       "2020-09-12 20:10:58  the unsolicited mail in ballot scam is a major...   \n",
       "2020-10-23 22:04:14  thank you to all of the great american patriot...   \n",
       "2020-10-12 22:22:39  i m running as a proud democrat for the senate...   \n",
       "2020-10-23 19:50:48                                                      \n",
       "2020-10-23 19:49:55                                                      \n",
       "\n",
       "                                                             term_list  \\\n",
       "datetime                                                                 \n",
       "2020-09-12 20:10:58  [unsolicited, mail, ballot, scam, major, threa...   \n",
       "2020-10-23 22:04:14  [thank, to, of, great, american, patriots, the...   \n",
       "2020-10-12 22:22:39  [m, running, a, proud, democrat, the, senate, ...   \n",
       "2020-10-23 19:50:48                                                 []   \n",
       "2020-10-23 19:49:55                                                 []   \n",
       "\n",
       "                                                            term_count  \\\n",
       "datetime                                                                 \n",
       "2020-09-12 20:10:58  {'a': 1, 'ballot': 1, 'fraud': 1, 'smaller': 1...   \n",
       "2020-10-23 22:04:14  {'great': 1, 'patriots': 1, 'american': 1, 'th...   \n",
       "2020-10-12 22:22:39  {'a': 1, 's': 1, 'm': 1, 'sleepy': 1, 'china':...   \n",
       "2020-10-23 19:50:48                                                 {}   \n",
       "2020-10-23 19:49:55                                                 {}   \n",
       "\n",
       "                                                                    TF  \\\n",
       "datetime                                                                 \n",
       "2020-09-12 20:10:58  {'a': 0.02857142857142857, 'ballot': 0.0285714...   \n",
       "2020-10-23 22:04:14  {'great': 0.1, 'patriots': 0.1, 'american': 0....   \n",
       "2020-10-12 22:22:39  {'a': 0.045454545454545456, 's': 0.04545454545...   \n",
       "2020-10-23 19:50:48                                                 {}   \n",
       "2020-10-23 19:49:55                                                 {}   \n",
       "\n",
       "                                                                 TFIDF  \n",
       "datetime                                                                \n",
       "2020-09-12 20:10:58  {'a': 0.06206252854785413, 'ballot': 0.1258794...  \n",
       "2020-10-23 22:04:14  {'great': 0.24709204078132607, 'patriots': 0.5...  \n",
       "2020-10-12 22:22:39  {'a': 0.09873584087158611, 's': 0.153130090955...  \n",
       "2020-10-23 19:50:48                                                 {}  \n",
       "2020-10-23 19:49:55                                                 {}  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate TFIDFs for Trump\n",
    "trump_df, trump_idf, trump_corpus = TFIDF_processing(trump_df)\n",
    "trump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-08-11    [{'p': 1.1284985763305553, 'enjoy': 1.15883879...\n",
       "2020-08-12    [{'neworleansrta': 0.36678828940052893, 'usdot...\n",
       "2020-08-13    [{}, {'realdonaldtrump': 1.1366423080231316, '...\n",
       "2020-08-14    [{'buds': 0.4097886214584272, 'dimensional': 0...\n",
       "2020-08-15    [{}, {'for': 0.3350592538544098, 'moments': 0....\n",
       "Name: TFIDF, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate TFIDF scores by date for Trump\n",
    "trump_by_date = trump_df.groupby(\"date\")[\"TFIDF\"].apply(lambda x:x.to_list())\n",
    "\n",
    "score_df_trump = pd.DataFrame(trump_df.groupby(\"date\")[\"TFIDF\"].apply(lambda x: sum_normalize_collections(x.to_list())))\n",
    "\n",
    "score_df_trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_df_joe.to_csv('../../data/biden_tweet_scores.csv')\n",
    "score_df_donald.to_csv('../../data/trump_tweet_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/president_polls.csv does not exist: '../data/president_polls.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-b7cf8ba7169d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read in data, select relevant cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/president_polls.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'poll_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fte_grade'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sample_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'start_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'answer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pct'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/president_polls.csv does not exist: '../data/president_polls.csv'"
     ]
    }
   ],
   "source": [
    "# Read in data, select relevant cols\n",
    "ge = pd.read_csv('../data/president_polls.csv')\n",
    "ge = ge[['poll_id', 'fte_grade', 'sample_size', 'start_date', 'answer', 'pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use good polls (according to 538)\n",
    "ge = ge[ge['fte_grade'].isin(['A+', 'A', 'A-', 'A/B', 'B+', 'B'])]\n",
    "ge.drop('fte_grade', axis=1, inplace=True)\n",
    "\n",
    "# Set index to date\n",
    "ge['start_date'] = pd.to_datetime(ge['start_date'])\n",
    "ge.set_index('start_date', inplace=True)\n",
    "ge.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see the latest date with primary candidates still.\n",
    "ge[ge['answer'] == 'Sanders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all primary dates, only need Biden and Trump\n",
    "ge = ge[ge.index > '2020-04-06']\n",
    "ge = ge[ge.answer.isin(['Biden', 'Trump'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pivot table to get Biden and Trump pct in the same row\n",
    "runoff = ge.pivot_table('pct', ['start_date', 'poll_id', 'sample_size'], 'answer').reset_index().set_index('start_date')\n",
    "runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Weight percentages by sample sizes\n",
    "runoff['total_biden'] = runoff['Biden'] * runoff['sample_size']\n",
    "runoff['total_trump'] = runoff['Trump'] * runoff['sample_size']\n",
    "overall_runoff = runoff.groupby('start_date')[['sample_size', 'total_biden', 'total_trump']].sum().sort_index()\n",
    "overall_runoff['w_biden'] = overall_runoff['total_biden'] / overall_runoff['sample_size']\n",
    "overall_runoff['w_trump'] = overall_runoff['total_trump'] / overall_runoff['sample_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
